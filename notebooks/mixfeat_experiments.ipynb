{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac891d1b-65af-48f5-9c72-9e4a06346f1a",
   "metadata": {},
   "source": [
    "# Mixfeat session-level experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae84140-b1d2-4b35-8931-42ed84a4d159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "# update the path so we can directly import code from the DVlog\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"DVlog\"))))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir, \"DVlog\")))\n",
    "\n",
    "from DVlog.utils.bias_mitigations import apply_oversampling, apply_mixfeat_oversampling\n",
    "from DVlog.utils.metrics import calculate_performance_measures, calculate_gender_performance_measures, calculate_fairness_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e3e16-b07e-487a-bac3-c53ab6e8e638",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be37868a-0844-4ab3-a602-952538cdc246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations_file = Path(r\"../DVlog/dataset/dvlog_labels_v2.csv\")\n",
    "embeddings_path = Path(\"../DVlog/dataset/sent-embeddings-dataset\")\n",
    "feature_name = \"sent_mpnet_keyw\"\n",
    "\n",
    "random_seeds = [0, 1, 42, 1123, 3407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deee4490-f4a2-4a48-a727-46a565976d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label gender dataset\n",
       "0         0      1      f   train\n",
       "1         1      1      f    test\n",
       "2         2      1      m   train\n",
       "3         3      1      m   train\n",
       "4         4      1      f    test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the annotation labels\n",
    "df_annotations = pd.read_csv(annotations_file)\n",
    "df_annotations.reset_index(drop=True, inplace=True)\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2269ed5-cb8d-4166-9fe6-a009ded76988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>dataset</th>\n",
       "      <th>avg_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>train</td>\n",
       "      <td>[-0.0043204557, 0.0025047027, -0.022133984, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>[0.014702894, 0.017551864, -0.01323786, -0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>[-0.0020621587, -0.002233186, -0.009010282, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>[0.013287175, 0.005526411, -0.010409681, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>[-0.008224284, 0.02129893, -0.0096479375, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label gender dataset  \\\n",
       "0         0      1      f   train   \n",
       "1         1      1      f    test   \n",
       "2         2      1      m   train   \n",
       "3         3      1      m   train   \n",
       "4         4      1      f    test   \n",
       "\n",
       "                                           avg_embed  \n",
       "0  [-0.0043204557, 0.0025047027, -0.022133984, -0...  \n",
       "1  [0.014702894, 0.017551864, -0.01323786, -0.016...  \n",
       "2  [-0.0020621587, -0.002233186, -0.009010282, -0...  \n",
       "3  [0.013287175, 0.005526411, -0.010409681, -0.02...  \n",
       "4  [-0.008224284, 0.02129893, -0.0096479375, -0.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over each row and compute the average embeddings\n",
    "df_annotations[\"avg_embed\"] = None\n",
    "\n",
    "# loop over each row and retrieve the embeddings\n",
    "seq_length = 104\n",
    "\n",
    "for idx, row in df_annotations.iterrows():\n",
    "    # get the texts\n",
    "    video_id = row.video_id\n",
    "    \n",
    "    # setup the path to the file\n",
    "    embedding_path = os.path.join(embeddings_path, str(video_id), f\"{feature_name}.npy\")\n",
    "    embedding = np.load(embedding_path).astype(np.float32)\n",
    "\n",
    "    # apply the padding\n",
    "    padded_embedding = embedding[:seq_length]\n",
    "\n",
    "    # get the average over the whole embedding\n",
    "    avg_embedding = np.mean(padded_embedding, axis=0)\n",
    "    # std_embedding = np.std(padded_embedding, axis=0)\n",
    "\n",
    "    # put the embedding back\n",
    "    df_annotations.at[idx, \"avg_embed\"] = avg_embedding\n",
    "\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef9cfab-45ed-47ab-88d0-907f22788260",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 768) (662,) (662,)\n"
     ]
    }
   ],
   "source": [
    "# setup the train and validation datasets\n",
    "train_indices = df_annotations[df_annotations[\"dataset\"] == \"train\"].index\n",
    "val_indices = df_annotations[df_annotations[\"dataset\"] == \"val\"].index\n",
    "\n",
    "# prepare the features and labels\n",
    "avg_features = np.stack(df_annotations[\"avg_embed\"].values)\n",
    "labels = df_annotations[\"label\"].values\n",
    "genders = df_annotations[\"gender\"].values\n",
    "\n",
    "# create the train and validation sets\n",
    "X_train, X_val = avg_features[train_indices], avg_features[val_indices]\n",
    "y_train, y_val = labels[train_indices], labels[val_indices]\n",
    "\n",
    "# combine the train and validation sets\n",
    "X = np.vstack((X_train, X_val))\n",
    "y = np.hstack((y_train, y_val))\n",
    "\n",
    "# Create a test_fold array: -1 for training set, 0 for validation set\n",
    "test_fold = np.concatenate([\n",
    "    -1 * np.ones(len(X_train), dtype=int),\n",
    "    np.zeros(len(X_val), dtype=int)\n",
    "])\n",
    "\n",
    "print(X.shape, y.shape, test_fold.shape)\n",
    "\n",
    "# Create PredefinedSplit object\n",
    "ps = PredefinedSplit(test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed143f12-df7f-4606-9ad9-60bc683e8236",
   "metadata": {},
   "source": [
    "## setup the gridsearch with the parameters\n",
    "- C (Regularization Parameter): Controls the trade-off between achieving a low error on the training data and minimizing the norm of the weights. A small value for C makes the decision surface smooth, while a large value of C aims to classify all training examples correctly.\n",
    "\n",
    "- Gamma (Kernel Coefficient): Defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. It is applicable for 'rbf', 'poly', and 'sigmoid' kernels.\n",
    "\n",
    "- Kernel: Specifies the kernel type to be used in the algorithm. Common kernels are 'linear', 'poly' (polynomial), 'rbf' (radial basis function), and 'sigmoid'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cf8be3-bcda-43a5-9eb6-52ce7778cf13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 64 candidates, totalling 64 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the SVM and parameter grid\n",
    "svm = SVC(random_state=42)\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Set up and run GridSearchCV\n",
    "grid_search_avg = GridSearchCV(estimator=svm, param_grid=param_grid, cv=ps, verbose=2, n_jobs=-1)\n",
    "grid_search_avg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512909fa-6767-4d73-aa21-ce94624412ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 10, 'gamma': 1, 'kernel': 'poly'}\n",
      "Best validation score:  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# Output best parameters and score\n",
    "best_params = grid_search_avg.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best validation score: \", grid_search_avg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e57df055-aa1e-4fab-b90f-786c62677410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build the function for automatically retrieve all metrics\n",
    "def evaluate_model(y_true, y_pred, protected):\n",
    "\n",
    "    # calculate the performance metrics\n",
    "    w_precision, w_recall, w_fscore, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    # calculate the fairness metrics\n",
    "    eq_oppor, eq_acc, pred_equal, _, _ = calculate_fairness_measures(y_true, y_pred, protected, unprivileged='m')\n",
    "    \n",
    "    # eq_oppor, eq_acc, fairl_eq_odds, unpriv_stats, priv_stats = calculate_fairness_measures(y_true, y_pred, protected, 'm')\n",
    "    gender_metrics = calculate_gender_performance_measures(y_true, y_pred, protected)\n",
    "\n",
    "    measure_dict = {\n",
    "        \"precision\": w_precision,\n",
    "        \"recall\": w_recall,\n",
    "        \"fscore\": w_fscore,\n",
    "        f\"{gender_metrics[0][0]}_fscore\": gender_metrics[0][3],\n",
    "        f\"{gender_metrics[1][0]}_fscore\": gender_metrics[1][3],\n",
    "        \"eq_oppor\": eq_oppor,\n",
    "        \"eq_acc\": eq_acc,\n",
    "        \"pred_eq\": pred_equal}\n",
    "    return measure_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455bbd62-73fc-4929-9b76-ba46ea40c0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaulate this model on the test set\n",
    "test_indices = df_annotations[df_annotations[\"dataset\"] == \"test\"].index\n",
    "X_test, y_test, protec_test = avg_features[test_indices], labels[test_indices], genders[test_indices]\n",
    "\n",
    "# Evaluate the best model (avg)\n",
    "best_svm = grid_search_avg.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "base_eval_dict_avg = evaluate_model(y_test, y_pred, protec_test)\n",
    "\n",
    "# Evaluate the best model (std)\n",
    "# best_svm = grid_search_std.best_estimator_\n",
    "# y_pred = best_svm.predict(X_test_std)\n",
    "# base_eval_dict_std = evaluate_model(y_test, y_pred, protec_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f8661-c5f1-486e-b0e4-5e01e17a0c39",
   "metadata": {},
   "source": [
    "## Setup the bias mitigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c333cecd-cbc3-4886-8bd2-51cc30dcce2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: oversample with seed: 0\n",
      "Processing: group_upsample with seed: 0\n",
      "Processing: mixgender_upsample with seed: 0\n",
      "Processing: subgroup_upsample with seed: 0\n",
      "Processing: synthetic with seed: 0\n",
      "Processing: synthetic_mixgendered with seed: 0\n",
      "Processing: oversample with seed: 1\n",
      "Processing: group_upsample with seed: 1\n",
      "Processing: mixgender_upsample with seed: 1\n",
      "Processing: subgroup_upsample with seed: 1\n",
      "Processing: synthetic with seed: 1\n",
      "Processing: synthetic_mixgendered with seed: 1\n",
      "Processing: oversample with seed: 42\n",
      "Processing: group_upsample with seed: 42\n",
      "Processing: mixgender_upsample with seed: 42\n",
      "Processing: subgroup_upsample with seed: 42\n",
      "Processing: synthetic with seed: 42\n",
      "Processing: synthetic_mixgendered with seed: 42\n",
      "Processing: oversample with seed: 1123\n",
      "Processing: group_upsample with seed: 1123\n",
      "Processing: mixgender_upsample with seed: 1123\n",
      "Processing: subgroup_upsample with seed: 1123\n",
      "Processing: synthetic with seed: 1123\n",
      "Processing: synthetic_mixgendered with seed: 1123\n",
      "Processing: oversample with seed: 3407\n",
      "Processing: group_upsample with seed: 3407\n",
      "Processing: mixgender_upsample with seed: 3407\n",
      "Processing: subgroup_upsample with seed: 3407\n",
      "Processing: synthetic with seed: 3407\n",
      "Processing: synthetic_mixgendered with seed: 3407\n"
     ]
    }
   ],
   "source": [
    "mixfeat_options = ['oversample', 'group_upsample', 'mixgender_upsample', 'subgroup_upsample', 'synthetic', 'synthetic_mixgendered']\n",
    "results = [(\"base_model_avg\", base_eval_dict_avg)]\n",
    "\n",
    "# get the training section\n",
    "df_train = df_annotations[df_annotations[\"dataset\"] == \"train\"]\n",
    "\n",
    "# take the training_df and do the oversampling for each option\n",
    "for seed in random_seeds:\n",
    "    for option in mixfeat_options:\n",
    "        print(f\"Processing: {option} with seed: {seed}\")\n",
    "\n",
    "        # get the training section\n",
    "        df_copy = df_train.copy()\n",
    "        if option == 'oversample':\n",
    "            training_df = apply_oversampling(df_copy, seed)\n",
    "            X = np.stack(training_df[\"avg_embed\"].values)\n",
    "\n",
    "        else:\n",
    "            training_df = apply_mixfeat_oversampling(df_copy, option, 1, seed)\n",
    "\n",
    "            # extract the training data and apply the mixfeat operation whenever possible\n",
    "            X = []\n",
    "            for _, row in training_df.iterrows():\n",
    "                if row.mixfeat:\n",
    "                    idx1, idx2 = row.mixfeat\n",
    "                    prob = row.mixfeat_probs[0]\n",
    "\n",
    "                    # get the embeddings from the dataframe\n",
    "                    embedding1 = df_train.loc[df_train['video_id'] == idx1][\"avg_embed\"].values[0]\n",
    "                    embedding2 = df_train.loc[df_train['video_id'] == idx2][\"avg_embed\"].values[0]\n",
    "\n",
    "                    final_embedding = (embedding1 * prob) + (embedding2 * (1 - prob))\n",
    "                    X.append(final_embedding)\n",
    "                else:\n",
    "                    X.append(row.avg_embed)\n",
    "\n",
    "            # get all the information and train the model\n",
    "            X = np.array(X)\n",
    "\n",
    "        # retrieve the label information\n",
    "        y = training_df[\"label\"].values\n",
    "\n",
    "        # train an SVM model\n",
    "        svm = SVC(**best_params, random_state=seed)\n",
    "        svm.fit(X, y)\n",
    "\n",
    "        # evaluate the model\n",
    "        y_pred = svm.predict(X_test)\n",
    "        eval_dict = evaluate_model(y_test, y_pred, protec_test)\n",
    "        results.append((option, eval_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8e09b-8f04-4d5d-889f-3320ecf55e80",
   "metadata": {},
   "source": [
    "## Setup the post-processing bias mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca89f58-5566-4c03-bbcd-3b35f181e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results from the normal textual model\n",
    "best_svm = grid_search_avg.best_estimator_\n",
    "y_pred_train = best_svm.predict(X_train)\n",
    "y_pred_test = best_svm.predict(X_test)\n",
    "\n",
    "# set \n",
    "protec_train = genders[train_indices]\n",
    "protected_train = np.where(protec_train == \"m\", 0, 1)\n",
    "protected_test = np.where(protec_test == \"m\", 0, 1)\n",
    "    \n",
    "# Function to apply EqOddsPostprocessing\n",
    "def apply_eqodds(y_train_true, y_train_pred, y_test_pred, protected_attr_train, protected_attr_test, seed):\n",
    "    # Create BinaryLabelDataset for training data\n",
    "    dataset_train_true = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=pd.DataFrame({\n",
    "        'label': y_train_true,\n",
    "        'protected': protected_attr_train\n",
    "    }), label_names=['label'], protected_attribute_names=['protected'])\n",
    "\n",
    "    dataset_train_pred = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=pd.DataFrame({\n",
    "        'label': y_train_pred,\n",
    "        'protected': protected_attr_train\n",
    "    }), label_names=['label'], protected_attribute_names=['protected'])\n",
    "\n",
    "    # Create BinaryLabelDataset for test data\n",
    "    dataset_test_pred = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=pd.DataFrame({\n",
    "        'label': y_test_pred,\n",
    "        'protected': protected_attr_test\n",
    "    }), label_names=['label'], protected_attribute_names=['protected'])\n",
    "\n",
    "    # Apply EqOddsPostprocessing\n",
    "    eq_odds = EqOddsPostprocessing(unprivileged_groups=[{'protected': 0}],\n",
    "                                   privileged_groups=[{'protected': 1}], seed=seed)\n",
    "\n",
    "    eq_odds = eq_odds.fit(dataset_train_true, dataset_train_pred)\n",
    "    dataset_transf_test_pred = eq_odds.predict(dataset_test_pred)\n",
    "\n",
    "    # Extract the adjusted predictions\n",
    "    adjusted_pred = dataset_transf_test_pred.labels.ravel()\n",
    "    return adjusted_pred\n",
    "\n",
    "# \n",
    "for seed in random_seeds:\n",
    "    new_preds = apply_eqodds(y_train, y_pred_train, y_pred_test, protected_train, protected_test, seed)\n",
    "    eval_dict = evaluate_model(y_test, new_preds, protec_test)\n",
    "    results.append((\"eqodds\", eval_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcc61232-1f22-4b1f-9c01-904b9db0c723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Male F-score</th>\n",
       "      <th>Female F-score</th>\n",
       "      <th>eq_oppor</th>\n",
       "      <th>eq_acc</th>\n",
       "      <th>pred_eq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model_avg</th>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eqodds</th>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_upsample</th>\n",
       "      <td>0.9164</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixgender_upsample</th>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversample</th>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subgroup_upsample</th>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.948</td>\n",
       "      <td>1.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic</th>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic_mixgendered</th>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Precision  Recall  F-score  Male F-score  \\\n",
       "name                                                              \n",
       "base_model_avg            0.9220  0.9210   0.9210        0.8950   \n",
       "eqodds                    0.9160  0.9150   0.9150        0.8770   \n",
       "group_upsample            0.9164  0.9162   0.9162        0.8804   \n",
       "mixgender_upsample        0.9140  0.9138   0.9138        0.8760   \n",
       "oversample                0.9190  0.9174   0.9174        0.8876   \n",
       "subgroup_upsample         0.9042  0.8886   0.8864        0.8538   \n",
       "synthetic                 0.9216  0.9198   0.9198        0.8948   \n",
       "synthetic_mixgendered     0.8708  0.8300   0.8228        0.7990   \n",
       "\n",
       "                       Female F-score  eq_oppor  eq_acc  pred_eq  \n",
       "name                                                              \n",
       "base_model_avg                 0.9350     0.880   0.960    0.720  \n",
       "eqodds                         0.9350     0.880   0.940    0.970  \n",
       "group_upsample                 0.9350     0.856   0.944    0.722  \n",
       "mixgender_upsample             0.9332     0.818   0.942    0.496  \n",
       "oversample                     0.9330     0.902   0.954    0.938  \n",
       "subgroup_upsample              0.9040     0.976   0.948    1.268  \n",
       "synthetic                      0.9330     0.916   0.962    0.936  \n",
       "synthetic_mixgendered          0.8352     1.000   0.958    1.130  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data into a structured format\n",
    "extracted_data = []\n",
    "for name, result in results:\n",
    "    data = {\n",
    "        \"name\": name,\n",
    "        \"Precision\": np.round(result[\"precision\"], 3),\n",
    "        \"Recall\": np.round(result[\"recall\"], 3),\n",
    "        \"F-score\": np.round(result[\"fscore\"], 3),\n",
    "        \"Male F-score\": np.round(result[\"m_fscore\"], 3),\n",
    "        \"Female F-score\": np.round(result[\"f_fscore\"], 3),\n",
    "        \"eq_oppor\": np.round(result[\"eq_oppor\"], 2),\n",
    "        \"eq_acc\": np.round(result[\"eq_acc\"], 2),\n",
    "        \"pred_eq\": np.round(result[\"pred_eq\"], 2)\n",
    "    }\n",
    "    extracted_data.append(data)\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame and display it\n",
    "df = pd.DataFrame(extracted_data)\n",
    "df.groupby(\"name\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6126d807-8da6-42d8-9dbb-04d8ca0624c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Male F-score</th>\n",
       "      <th>Female F-score</th>\n",
       "      <th>eq_oppor</th>\n",
       "      <th>eq_acc</th>\n",
       "      <th>pred_eq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base_model_avg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eqodds</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_upsample</th>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>0.173263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixgender_upsample</th>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.035777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversample</th>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>0.127945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subgroup_upsample</th>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.013416</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.064962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic</th>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.035071</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.215012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic_mixgendered</th>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.042426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Precision    Recall   F-score  Male F-score  \\\n",
       "name                                                                 \n",
       "base_model_avg               NaN       NaN       NaN           NaN   \n",
       "eqodds                  0.000000  0.000000  0.000000      0.000000   \n",
       "group_upsample          0.002608  0.002683  0.002683      0.007603   \n",
       "mixgender_upsample      0.002828  0.002683  0.002683      0.000000   \n",
       "oversample              0.005788  0.005367  0.005367      0.015710   \n",
       "subgroup_upsample       0.001789  0.003286  0.003578      0.008319   \n",
       "synthetic               0.006580  0.006573  0.006573      0.012377   \n",
       "synthetic_mixgendered   0.002490  0.004243  0.004604      0.000000   \n",
       "\n",
       "                       Female F-score  eq_oppor    eq_acc   pred_eq  \n",
       "name                                                                 \n",
       "base_model_avg                    NaN       NaN       NaN       NaN  \n",
       "eqodds                       0.000000  0.000000  0.000000  0.000000  \n",
       "group_upsample               0.000000  0.013416  0.008944  0.173263  \n",
       "mixgender_upsample           0.004025  0.010954  0.004472  0.035777  \n",
       "oversample                   0.004472  0.045497  0.019494  0.127945  \n",
       "subgroup_upsample            0.004472  0.013416  0.010954  0.064962  \n",
       "synthetic                    0.004472  0.035071  0.010954  0.215012  \n",
       "synthetic_mixgendered        0.007430  0.000000  0.010954  0.042426  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"name\").std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
