{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4ca3a8-3c27-46f3-a5f4-5cf16954599f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b214672-8c25-4402-a9b5-a8d5a29f6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865fbc7-f4db-4bef-aa05-167f1a3e7ecc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c98b12c-dee3-4f08-b3b2-62f99df854d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = Path(r\"../data/dvlog_text\")\n",
    "annotations_file = Path(r\"../DVlog/dataset/dvlog_labels_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20af4467-7b0f-41d3-ad3d-4484a9a518ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label gender dataset\n",
       "0         0      1      f   train\n",
       "1         1      1      f    test\n",
       "2         2      1      m   train\n",
       "3         3      1      m   train\n",
       "4         4      1      f    test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the annotation labels\n",
    "df_annotations = pd.read_csv(annotations_file)\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da6206f-aa00-419d-9dc9-84af247c2569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over each text file and extract the text\n",
    "text_ref_dict = {}\n",
    "\n",
    "for json_file in os.listdir(json_dir):\n",
    "    \n",
    "    # get the video_id and setup the path to the file\n",
    "    video_id = int(json_file.split(\"_\")[0])\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    \n",
    "    with open(json_path) as current_file:\n",
    "        json_dict = json.loads(current_file.read())\n",
    "\n",
    "    text_ref_dict[video_id] = json_dict[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f346cddb-ab14-4df8-84f4-2295910b0cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>train</td>\n",
       "      <td>So I wanted to come on here and sit down with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>Hello guys, it's me again and I'm going to ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>Welcome back to another video today. I'm goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>Hi everybody and welcome to and the clouds br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>Hey, me and McCrown, me and my hairy hair pit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label gender dataset  \\\n",
       "0         0      1      f   train   \n",
       "1         1      1      f    test   \n",
       "2         2      1      m   train   \n",
       "3         3      1      m   train   \n",
       "4         4      1      f    test   \n",
       "\n",
       "                                                text  \n",
       "0   So I wanted to come on here and sit down with...  \n",
       "1   Hello guys, it's me again and I'm going to ta...  \n",
       "2   Welcome back to another video today. I'm goin...  \n",
       "3   Hi everybody and welcome to and the clouds br...  \n",
       "4   Hey, me and McCrown, me and my hairy hair pit...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the annotations back into the dataframe\n",
    "df_annotations[\"text\"] = df_annotations[\"video_id\"].apply(lambda x: text_ref_dict.get(x))\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189cf38-645f-4f3e-a5cc-3b04ee7daa51",
   "metadata": {},
   "source": [
    "##\n",
    "train with xgboost and 1 for every word\n",
    "train with xgboost and 1 for every word and remove certain keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a7b2d6-f29e-4b11-827a-820cd8537111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "      <th>dataset</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>train</td>\n",
       "      <td>So I wanted to come on here and sit down with...</td>\n",
       "      <td>wanted come sit guy kind talk vent really stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>Hello guys, it's me again and I'm going to ta...</td>\n",
       "      <td>hello guy im going talk today survive depressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>Welcome back to another video today. I'm goin...</td>\n",
       "      <td>welcome back another video today im going expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>train</td>\n",
       "      <td>Hi everybody and welcome to and the clouds br...</td>\n",
       "      <td>hi everybody welcome cloud break time talked m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>test</td>\n",
       "      <td>Hey, me and McCrown, me and my hairy hair pit...</td>\n",
       "      <td>hey mccrown hairy hair pit im mess im mess hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  label gender dataset  \\\n",
       "0         0      1      f   train   \n",
       "1         1      1      f    test   \n",
       "2         2      1      m   train   \n",
       "3         3      1      m   train   \n",
       "4         4      1      f    test   \n",
       "\n",
       "                                                text  \\\n",
       "0   So I wanted to come on here and sit down with...   \n",
       "1   Hello guys, it's me again and I'm going to ta...   \n",
       "2   Welcome back to another video today. I'm goin...   \n",
       "3   Hi everybody and welcome to and the clouds br...   \n",
       "4   Hey, me and McCrown, me and my hairy hair pit...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  wanted come sit guy kind talk vent really stru...  \n",
       "1  hello guy im going talk today survive depressi...  \n",
       "2  welcome back another video today im going expl...  \n",
       "3  hi everybody welcome cloud break time talked m...  \n",
       "4  hey mccrown hairy hair pit im mess im mess hea...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some preprocessing to shrink the vocabulary (including lemmatization)\n",
    "def preprocess_string(text: str, stop_words: set = set(stopwords.words(\"english\")), unicode_pattern: str = \"NFKD\") -> str:\n",
    "    text = text.replace(\"\\n\", \" \").strip()  # Remove newlines and trailing whitespace\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove puctuation with lookup table\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.digits))  # Remove all numbers with lookup table\n",
    "    \n",
    "    # Remove excess whitespace in between words\n",
    "    # E.g. the sentence \"for 10 days\" becomes \"for days\" instead of \"for  days\" with two spaces\n",
    "    text = \" \".join(text.split())\n",
    "    text = unicodedata.normalize(unicode_pattern, text)  # Strip accents from characters\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmanizer = nltk.stem.WordNetLemmatizer()\n",
    "    text = \" \".join([lemmanizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    return text\n",
    "\n",
    "df_annotations[\"preprocessed\"] = df_annotations[\"text\"].apply(preprocess_string)\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927f277-38ec-4ee1-b74a-832ce5d032e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "207524c0-fc45-41a6-a680-becc2bc5ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data subsets\n",
    "df_train = df_annotations[df_annotations[\"dataset\"] == \"train\"]\n",
    "df_test = df_annotations[df_annotations[\"dataset\"] == \"test\"]\n",
    "df_val = df_annotations[df_annotations[\"dataset\"] == \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc39829-4163-48a3-b1f1-65030de3e17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup the bag of words model\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train[\"preprocessed\"].to_list())\n",
    "\n",
    "# retrieve the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# set the count vectorizer to 0 or 1\n",
    "X_train = X_train.toarray()\n",
    "X_train = np.where(X_train > 1, 1, X_train)\n",
    "y_train = df_train[\"label\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3798d4d8-00e0-4623-9283-efc5c7f9b446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup the evaluation script\n",
    "def calculate_performance_measures(y_true, y_pred):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-score: {fscore}\\n--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0060731e-8a60-4ff7-9c08-7d05f45cf6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9965397923875432\n",
      "Precision: 0.9965397923875432\n",
      "Recall: 0.9965397923875432\n",
      "F1-score: 0.9965397923875432\n"
     ]
    }
   ],
   "source": [
    "# train a randomforestclassifier\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the train set\n",
    "y_pred = clf.predict(X_train)\n",
    "calculate_performance_measures(y_train, y_pred)\n",
    "\n",
    "# evaluate the model on the eval set\n",
    "X_val = vectorizer.fit_transform(df_train[\"preprocessed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e50930-a09d-4f1a-abee-2f68f3d181b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the feature importances\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "forest_importances\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "# ax.set_title(\"Feature importances using MDI\")\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "# fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
